# カエデのAIニュース【2026年02月17日】

> 今日は39件！注目のAIニュースが目白押しの火曜日です。

## 目次

1. [Anthropic] Anthropicがインドに新拠点
2. [Gemini CLI] Gemini CLI拡張機能が公開
3. [Google for Developers] Genkitが主要クラウドに対応
4. [Google Antigravity] スクショからUIをAI編集
5. [NVIDIA] NVIDIA GB300発表
6. [NVIDIA] Blackwell Ultra性能向上
7. [NVIDIA] NVIDIA GB300発表
8. [NVIDIA AI Developer] Blackwell Ultra、50倍高速化
9. [NVIDIA AI Developer] Qwen 3.5提供開始
10. [GitHub] GitHub Copilot新記憶機能
11. [Kilo] Grok Code Fast最適化版発表
12. [Kilo] Kiloが最新2モデルを無料提供
13. [Kilo] GLM-5発表、無料公開中
14. [Kilo] OpenAI、次世代エージェント責任者任命
15. [Kilo] MiniMax M2.5が登場
16. [ollama] Qwen3.5がOllamaで公開
17. [Hugging Face] Dots.ocr 1.5がSOTAを記録
18. [Hugging Face] Qwen3.5-397B公開
19. [Manus] Manus Agents発表
20. [Kiro] Kiroが最新AI3種に対応
21. [Kiro] AIデバッグ支援BugSight登場
22. [Mistral Vibe] Mistral Vibeのデザイン刷新
23. [Qwen] QwenがUnslothに対応
24. [Qwen] Qwen3.5-397B公開
25. [Qwen] Qwen VLMの最新性能公開
26. [Qwen] Qwenモデルの性能評価を公開
27. [Qwen] QwenがNVIDIA NIMに対応
28. [Qwen] Qwenが農場ゲームを生成
29. [Qwen] Qwen Codeが自動PR提出に対応
30. [Qwen] Qwen-Agentの公式コード公開
31. [Qwen] Qwen2.5-Coder-32B発表
32. [Qwen] Qwen3.5がリリース
33. [Qwen] Qwenに思考・検索機能追加
34. [Qwen] Qwen2.5-Turbo発表
35. [Qwen] Qwen環境スケーリング研究
36. [MiniMax (official)] MiniMax M2.5提供開始
37. [MiniMax (official)] MiniMax M2.5がAPI公開
38. [MiniMax (official)] MiniMaxが新モデルM2.5発表
39. [MiniMax (official)] M2.5の推論効率を実証

---

## 1. 【Anthropic】Anthropicがインドに新拠点

Anthropicは、インドのベンガルールに新たなオフィスを開設したことを発表しました。これは同社にとってアジア太平洋地域で2番目の拠点となります。インドは現在、claude.aiの利用者数において世界で2番目に大きな市場となっており、今回の拠点開設は同市場への長期的なコミットメントを強化するものです。あわせて新たなパートナーシップの開始も公表されており、インド国内におけるAIエコシステムの拡大とサービス展開の加速を目指しています。

https://x.com/AnthropicAI/status/2023322514206957688

---

## 2. 【Gemini CLI】Gemini CLI拡張機能が公開

Gemini CLIに拡張機能（Extensions）が導入されました。第一弾としてMiroとの連携が可能になり、ターミナルからプロンプトを入力するだけで、図解やドキュメント、テーブルを自動生成して複雑なタスクを構造化できます。開発者はコマンドライン環境を離れることなく、Geminiを介して使い慣れた外部ツールを操作でき、ワークフローの自動化と開発サイクルの高速化が期待されます。

https://x.com/geminicli/status/2023487122523779476

---

## 3. 【Google for Developers】Genkitが主要クラウドに対応

Googleが提供するAIアプリケーション開発用フレームワーク「Genkit」において、Amazon BedrockおよびAzure AI Foundryの公式サポートが開始されました。このアップデートはGenkitのGo版とJavaScript版（JS）の両方が対象です。これにより、開発者はGenkitを用いて、複数のクラウドプラットフォーム間で互換性のあるAIアプリケーションを構築することが可能になります。Google Cloud以外の主要なクラウドAIサービスとの統合が公式にサポートされたことで、開発における柔軟性とポータビリティが大幅に向上しました。

https://x.com/googledevs/status/2023457350896558419

---

## 4. 【Google Antigravity】スクショからUIをAI編集

GoogleのAntigravityは、スクリーンショットの特定の範囲を選択し、AIエージェントに指示を出すだけでUIレイアウトを即座に変更できる機能を発表しました。従来のような長文のプロンプトを必要とせず、視覚的な指定と自然言語の組み合わせにより、直感的なUI調整が可能です。「ここをこう変えたい」という意図を伝えるだけで修正が完了するため、デザインの反復プロセスを大幅に効率化します。

https://x.com/antigravity/status/2023462064480559140

---

## 5. 【NVIDIA】NVIDIA GB300発表

NVIDIAは、Hopperプラットフォームから大幅な進化を遂げた次世代の推論向けプラットフォーム「NVIDIA GB300 NVL72」を発表しました。このシステムは、ワットあたりの性能が従来比で50倍向上しており、100万トークンあたりのコストを35倍削減することに成功しています。推論パフォーマンスにおいて圧倒的な優位性を示しており、AIモデルの運用効率と経済性を劇的に改善する画期的な技術アップデートです。

https://x.com/nvidia/status/2023479202981224472

---

## 6. 【NVIDIA】Blackwell Ultra性能向上

NVIDIAは、Blackwell UltraがエージェントAIにおいて、従来比で最大50倍の性能向上と35倍のコスト削減を実現することを発表しました。クラウドプロバイダーは、低遅延や長いコンテキストが求められるコーディングアシスタント等の用途向けに、NVIDIA GB300 NVL72システムの本格的な導入を開始しています。このシステムは、複雑な推論を伴う自律型AIの処理効率を劇的に改善する設計となっています。

https://x.com/nvidia/status/2023442916115427787

---

## 7. 【NVIDIA】NVIDIA GB300発表

NVIDIAは、最新のGB300 NVL72を発表しました。NVIDIA DynamoおよびTensorRT-LLMを含む共同設計されたソフトウェアスタックを組み合わせることで、従来のHopperプラットフォームと比較してワットあたりの性能が50倍以上に向上しています。この電力効率の大幅な改善により、AIモデルの推論や学習におけるエネルギー効率が飛躍的に高まることが期待されます。

https://x.com/nvidia/status/2023448139190202479

---

## 8. 【NVIDIA AI Developer】Blackwell Ultra、50倍高速化

NVIDIAは、次世代GPUアーキテクチャ「Blackwell Ultra」の最新データを公開しました。この新チップは、エージェンティックAI（自律型AI）の処理において、従来比で最大50倍のパフォーマンス向上と、35倍のコスト削減を実現します。これにより、複雑な推論や自律的なタスクを実行するAIエージェントの開発・運用効率が劇的に向上することが期待されます。主要なクラウドプロバイダーへの導入も進む見通しです。

https://x.com/NVIDIAAIDev/status/2023473209312768080

---

## 9. 【NVIDIA AI Developer】Qwen 3.5提供開始

AlibabaのQwenチームが、新モデル「Qwen 3.5」シリーズから「Qwen3.5-397B-A17B」をリリースしました。NVIDIAはこの発表を祝福し、開発者が無料で構築を開始できるプラットフォームを提供しています。また、NVIDIA NeMoを使用することで、モデルのダウンロードやカスタマイズも可能です。大規模なパラメータを持つこのモデルは、開発者向けに即座に利用可能な状態で公開されています。

https://x.com/NVIDIAAIDev/status/2023458975312986381

---

## 10. 【GitHub】GitHub Copilot新記憶機能

GitHubは、GitHub Copilotに「エージェント記憶（agentic memory）」システムを導入し、その技術的アーキテクチャを公開しました。この新機能により、Copilotはユーザーのコーディングスタイルやプロジェクトの文脈を学習・保持し、よりパーソナライズされた高度なコーディング支援を実現します。過去の対話内容や開発環境の情報を記憶することで、長期的な文脈に沿った正確な提案が可能になります。これにより、開発者は個々のプロジェクトに最適化された、よりスマートで効率的な開発体験を享受できるようになります。

https://x.com/github/status/2023441003802214828

---

## 11. 【Kilo】Grok Code Fast最適化版発表

xAIのAIモデルであるGrokにおいて、コーディングに特化した機能「Grok Code Fast」の最適化版が発表されました。従来の高速性に加え、さらなる最適化が施されたことで、コーディング支援の効率とパフォーマンスが向上しています。開発者向けの機能として、より迅速かつ精度の高いコード生成や補完が期待されます。

https://x.com/kilocode/status/2023460550248714409

---

## 12. 【Kilo】Kiloが最新2モデルを無料提供

Kilo CLIおよびKilo Codeにおいて、先週リリースされた最新AIモデル「GLM-5」と「MiniMax 2.5」が追加されました。これらのモデルは現在、同ツールを通じて100%無料で利用可能です。Artificial Analysisのリーダーボードでも注目される高性能なモデルを、開発者はコストをかけずに直接試用することができます。

https://x.com/kilocode/status/2023419101863976989

---

## 13. 【Kilo】GLM-5発表、無料公開中

Kilo CodeがOpenRouterのデイリーリーダーボードで1位を獲得しました。同サービスはZhipu AIの最新モデル「GLM-5」を採用しており、昨日は2,220億トークンの処理を記録しました。GLM-5は複数のベンチマークにおいてOpus 4.5/4.6を上回る性能を示しているとされています。現在、Kilo CodeではGLM-5への無料アクセスを日曜日まで提供しています。

https://x.com/kilocode/status/2023352685722759597

---

## 14. 【Kilo】OpenAI、次世代エージェント責任者任命

著名なAIエージェント開発者のPeter Steinberger氏が、OpenAIに参画したことが明らかになりました。同氏は個人で開発したエージェントがGitHubで累計20万スターを獲得するなど、極めて高い技術力で知られています。OpenAIでは「次世代のパーソナルエージェント」開発チームのリードを担当します。大手AIラボに匹敵する成果を個人で成し遂げた同氏の加入は、OpenAIが今後、より高度で実用的な自律型エージェントの開発を加速させる重要な人事戦略であると考えられます。

https://x.com/kilocode/status/2023249159290003822

---

## 15. 【Kilo】MiniMax M2.5が登場

MiniMax社が開発したAIモデル「MiniMax-M2.5」が、主要なベンチマークで優れた成績を収めていることが報告されました。実際の利用ユーザーからは、数値上のベンチマーク以上に実環境でのパフォーマンスが強力であるとの評価も得られています。現在、このモデルはKILO CODEを通じて完全に無料で試用することが可能です。

https://x.com/kilocode/status/2023155846826635278

---

## 16. 【ollama】Qwen3.5がOllamaで公開

Ollamaは、Qwen3.5シリーズ初となるオープンウェイトモデル「Qwen3.5-397B-A17B」の提供を開始しました。このモデルはOllamaのクラウド上で即座に利用可能となっており、「ollama run qwen3.5:cloud」コマンドで実行できます。大規模なパラメータ数を持つQwen3.5シリーズの最新成果を、Ollamaのプラットフォームを通じて手軽に試すことが可能になりました。

https://x.com/ollama/status/2023334181804069099

---

## 17. 【Hugging Face】Dots.ocr 1.5がSOTAを記録

OCRモデルの最新バージョン「Dots.ocr 1.5」が、ベンチマークであるOlmOCRBenchにおいてSOTA（最先端）の性能を記録しました。Dots.ocrは従来より高性能なOCRとして評価されていましたが、今回のアップデートにより、文字認識タスクにおける精度がさらに向上したことが示されています。

https://x.com/huggingface/status/2023382621196366330

---

## 18. 【Hugging Face】Qwen3.5-397B公開

AlibabaのQwenチームは、Qwen3.5シリーズ初となるオープン重みモデル「Qwen3.5-397B-A17B」を公開しました。本モデルは、現実世界のタスクに対応するためにトレーニングされたネイティブなマルチモーダルモデルです。Qwen3.5世代の幕開けとなる重要なリリースであり、大規模なパラメータ数を持ちながらオープンな利用が可能です。Hugging Face上でもリツイートされ、AIコミュニティから大きな注目を集めています。

https://x.com/huggingface/status/2023345144238649463

---

## 19. 【Manus】Manus Agents発表

Manusは、チャット内で動作するパーソナライズされたAIエージェント「Manus Agents」を発表しました。このエージェントは長期記憶機能を備えており、ユーザーのスタイルや好みを学習・保持します。また、1つのメッセージから動画、スライド、ウェブサイト、画像を生成するManusの全機能をチャット上で利用可能です。さらに、Gmail、Googleカレンダー、Notionなどの外部ツールとの連携にも対応しており、個々のユーザーに最適化された高度な自動化を実現します。

https://x.com/ManusAI/status/2023412626428932494

---

## 20. 【Kiro】Kiroが最新AI3種に対応

AI開発プラットフォームのKiroは、新たに3つのオープンウェイトモデル「DeepSeek 3.2」「Minimax 2.1」「Qwen3 Coder Next」を導入したことを発表しました。ユーザーはIDE内のピッカー、またはCLIで「/model」コマンドを実行することで、モデルを簡単に切り替えることができます。プロジェクトごとの要件やトレードオフに合わせて最適なモデルを選択できる環境が整いました。

https://x.com/kirodotdev/status/2023453228164145342

---

## 21. 【Kiro】AIデバッグ支援BugSight登場

AIを活用したデバッグ支援ツール「BugSight」がリリースされました。このツールは、開発者が理解に苦しむ難解なエラーメッセージの分析や解決をサポートするAIアシスタントです。デバッグ作業に費やす時間を削減し、開発効率を向上させることを目的として開発されました。

https://x.com/kirodotdev/status/2023442803318026681

---

## 22. 【Mistral Vibe】Mistral Vibeのデザイン刷新

Mistral AI向けのインターフェースツールである「Mistral Vibe」が、デザインの刷新（glow-up）を発表しました。最新のアップデートにより、ユーザーが使用しているターミナルの外観やテーマに合わせたデザインへと変更されています。これにより、開発環境との視覚的な親和性が高まり、ターミナル上でのユーザー体験が向上しています。

https://x.com/mistralvibe/status/2023411043310129596

---

## 23. 【Qwen】QwenがUnslothに対応

UnslothAIがQwenの最新モデルに対して、リリース初日からの「Day 0」サポートを開始しました。Unslothは大規模言語モデル（LLM）のファインチューニングを高速化・効率化するライブラリです。今回の統合により、開発者はQwenの最新モデルをより少ない計算リソースで、かつ迅速に微調整（fine-tuning）することが可能になります。

https://x.com/Alibaba_Qwen/status/2023383628596830529

---

## 24. 【Qwen】Qwen3.5-397B公開

AlibabaのQwenチームは、Qwen3.5シリーズ初となるオープンウェイトモデル「Qwen3.5-397B-A17B」を公開しました。このモデルはネイティブ・マルチモーダル対応で、実世界のエージェント向けに訓練されています。技術面では、ハイブリッド線形アテンションとスパースMoE、大規模な強化学習（RL）環境のスケーリングを採用しています。特筆すべき点として、Qwen3-Maxと比較してデコーディングのスループットが8.6倍から19.0倍へと劇的に向上しており、極めて高速な推論性能を実現しています。

https://x.com/Alibaba_Qwen/status/2023331062433153103

---

## 25. 【Qwen】Qwen VLMの最新性能公開

Alibaba CloudのQwenチームが、視覚と言語を統合したVision Language Model（VLM）の最新のベンチマーク性能を公開しました。文書理解、マルチリンガルOCR、動画解析などの主要な視覚タスクにおいて、既存の主要モデルに匹敵、あるいは上回る高い性能を示しています。特にQwen2-VLシリーズは、高解像度画像の認識や複雑な視覚的推論において優れた成果を上げており、オープンソースモデルとしての技術的な優位性を強調しています。

https://x.com/Alibaba_Qwen/status/2023353925148242315

---

## 26. 【Qwen】Qwenモデルの性能評価を公開

Alibaba CloudのQwenチームが、大規模言語モデル（LLM）のパフォーマンスに関するベンチマーク結果を公開しました。このデータには推論速度、スループット、メモリ効率などの重要な指標が含まれており、Qwenモデルが既存のモデルと比較して高いパフォーマンスを発揮していることが示されています。開発者が用途に応じた最適なモデルを選択するための技術的な指標として、非常に価値のある情報です。

https://x.com/Alibaba_Qwen/status/2023353822152917176

---

## 27. 【Qwen】QwenがNVIDIA NIMに対応

Alibabaの大規模言語モデルQwenが、NVIDIAの推論マイクロサービスである「NVIDIA NIM」に対応しました。これにより、開発者はNIM上でQwenを利用した開発を無料で開始できるほか、NVIDIA NeMoのフレームワークを用いてモデルのファインチューニングを行うことが可能です。今回の統合により、最適化された環境でQwenモデルの迅速なデプロイと、特定の用途に合わせた高度なカスタマイズが容易になりました。

https://x.com/Alibaba_Qwen/status/2023347919345336420

---

## 28. 【Qwen】Qwenが農場ゲームを生成

AlibabaのAIモデル「Qwen」が、単一のHTMLおよびJavaScriptファイルのみで構築された農場シミュレーションゲームを公開しました。「Stardew Valley」風のスタイルを持つこのゲームは、複雑なロジックや描画処理を一つのファイル内に完結させるQwenの高度なコーディング能力とコンテキスト保持能力を実証しています。AIがプロンプトから実用的なアプリケーションを即座に生成できる可能性を示す具体例となっています。

https://x.com/Alibaba_Qwen/status/2023341532678631870

---

## 29. 【Qwen】Qwen Codeが自動PR提出に対応

AlibabaのQwenチームが、ソフトウェアの不具合（Issue）を自律的に解決し、プルリクエスト（PR）を自動で作成・提出できる新機能「Qwen Code」を発表しました。この技術は、コードの修正から提出までのワークフローをAIが自律的に実行することを可能にします。AIによるソフトウェア開発の自動化をさらに前進させる重要なリリースであり、開発者の生産性向上に寄与することが期待されます。

https://x.com/Alibaba_Qwen/status/2023339169217728723

---

## 30. 【Qwen】Qwen-Agentの公式コード公開

AlibabaのQwenチームが、AIエージェント構築用フレームワーク「Qwen-Agent」のサンプルコードを公開しました。このフレームワークは、Qwenシリーズの大型言語モデルを活用し、ツール利用、RAG（検索拡張生成）、マルチエージェントシステムなどの高度な機能を実装するための基盤を提供します。公開されたリポジトリには具体的な実装例が含まれており、開発者はこれを利用して複雑なタスクを自動化するAIアプリケーションの構築を迅速に開始できます。オープンソースプロジェクトとしての透明性と実用性を高める取り組みです。

https://x.com/Alibaba_Qwen/status/2023337766176817296

---

## 31. 【Qwen】Qwen2.5-Coder-32B発表

Alibaba CloudのQwenチームは、コーディング特化型の最新モデル「Qwen2.5-Coder-32B」を公開しました。このモデルは320億パラメータを持ち、コーディング能力においてGPT-4oに匹敵する極めて高い性能を実現しています。数学的推論や多言語プログラミングへの対応が大幅に強化され、主要なベンチマークでオープンソースモデルとして最高水準の評価を得ています。Apache 2.0ライセンスで提供されており、開発者は商用・非商用を問わず自由に利用可能です。オープンソースのAI開発における強力な選択肢となります。

https://x.com/Alibaba_Qwen/status/2023336014975275206

---

## 32. 【Qwen】Qwen3.5がリリース

Alibaba CloudのQwenチームが、次世代AIモデル「Qwen3.5」を発表しました。Qwenシリーズは、高い言語処理能力と多言語対応を特徴とするオープンソースの大規模言語モデル（LLM）として広く知られています。今回の最新バージョンでは、従来のモデルからのさらなる性能向上や、推論能力の強化が期待されます。GitHubや公式ブログを通じて詳細な情報が順次公開される見込みであり、AI開発コミュニティにとって重要な技術的アップデートとなります。

https://x.com/Alibaba_Qwen/status/2023335333895741778

---

## 33. 【Qwen】Qwenに思考・検索機能追加

AlibabaのAIチーム「Qwen」は、公式チャットプラットフォーム（qwen.chat）において、新たな機能「Think（思考）」「Search（検索）」「Create（作成）」をリリースしました。これにより、推論プロセスを可視化する推論機能や、リアルタイムのWeb検索機能、そして成果物を生成するクリエイティブ機能が統合されました。最新のQwenモデルを活用し、高度な推論と情報検索をシームレスに行うことが可能です。ChatGPTやPerplexityに匹敵する多機能なチャットインターフェースへと進化しました。

https://x.com/Alibaba_Qwen/status/2023333682342412618

---

## 34. 【Qwen】Qwen2.5-Turbo発表

Alibaba Cloudは、最新のAIモデル「Qwen2.5-Turbo」を発表しました。本モデルは、最大100万トークンのコンテキストウィンドウをサポートしながら、処理速度とコスト効率を大幅に向上させているのが特徴です。GPT-4oなどの主要モデルと比較して、推論速度は3.6倍から6.8倍高速化されており、利用料金も大幅に低減されています。長文読解や大規模なデータ処理において、高いパフォーマンスと圧倒的なコストパフォーマンスを両立しており、現在はAPIを通じて利用可能です。

https://x.com/Alibaba_Qwen/status/2023333040706249180

---

## 35. 【Qwen】Qwen環境スケーリング研究

AlibabaのQwenチームは、LLMの評価における「環境スケーリング」に関する研究成果を公開しました。平均ランキングだけでなく、タスクの難易度や環境の変化がモデルの性能に与える影響を詳細に分析しています。特にQwen2.5-Math等のモデルを用い、計算リソースやデータの増加が特定の条件下でどのように精度向上に寄与するかを検証しており、従来のベンチマーク指標を補完する新たな評価の視点を提供しています。

https://x.com/Alibaba_Qwen/status/2023332906094195162

---

## 36. 【MiniMax (official)】MiniMax M2.5提供開始

MiniMaxは、最新AIモデル「MiniMax M2.5」をTogether AIのプラットフォームで提供開始しました。このモデルは、高度な構造化プランニング能力とコーディングにおけるSOTA（最先端）の性能を備えています。実用的なAIエージェントのワークフロー構築に最適化されており、Together AIとの提携を通じて、開発者は高性能な推論インフラ上で同モデルを利用可能になります。

https://x.com/MiniMax_AI/status/2023479508087824657

---

## 37. 【MiniMax (official)】MiniMax M2.5がAPI公開

MiniMax社が開発した最新AIモデル「MiniMax M2.5」が、BasetenのモデルAPI上で利用可能になりました。これにより、開発者は自身のアプリケーションやワークフローにMiniMax M2.5を容易に統合し、試用することが可能になります。APIを通じた提供開始により、同モデルの社会実装や開発における活用がさらに加速することが期待されます。

https://x.com/MiniMax_AI/status/2023471818519310710

---

## 38. 【MiniMax (official)】MiniMaxが新モデルM2.5発表

MiniMax社は、新モデル「M2.5」において強化学習（RL）の信号利用効率を大幅に改善したことを発表しました。トークンごとのプロセス報酬を採用することで、推論ステップにおける信号の無駄を省き、最先端のコーディング性能を極めて高いコスト効率で実現しています。本モデルはBasetenにてホストされており、高度な推論能力と経済性を両立させている点が特徴です。

https://x.com/MiniMax_AI/status/2023470874708549941

---

## 39. 【MiniMax (official)】M2.5の推論効率を実証

SemiAnalysisがMiniMaxの最新モデル「MiniMax M2.5」のベンチマーク結果を公開しました。vLLMプロジェクトと協力し、8枚のNVIDIA H200 TEP8構成で性能を測定。Time To First Token（TTFT）が10〜25秒という条件下において、M2.5が高い推論効率を実現していることが示されました。このデータは、大規模言語モデルの実運用におけるM2.5の技術的な優位性を裏付けるものとなっています。

https://x.com/MiniMax_AI/status/2023458329377599525

---
